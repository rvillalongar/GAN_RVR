{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "from models.VAE import VariationalAutoencoder\n",
    "from utils.loaders import load_mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "\n",
    "SECTION = 'vae'\n",
    "RUN_ID ='0002'\n",
    "DATA_NAME ='digits'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER +='_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode = 'build'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) , (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING: Logging before flag parsing goes to stderr.\nW0608 00:43:18.032642  4748 deprecation.py:506] From O:\\virtuelenv\\generative\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
    }
   ],
   "source": [
    "vae = VariationalAutoencoder(\n",
    "    input_dim=(28,28,1)\n",
    "    , encoder_conv_filters=[32,64,64,64]\n",
    "    , encoder_conv_kernel_size=[3,3,3,3]\n",
    "    , encoder_conv_strides=[1,2,2,1]\n",
    "    , decoder_conv_t_filters=[64,64,32,1]\n",
    "    , decoder_conv_t_kernel_size=[3,3,3,3]\n",
    "    , decoder_conv_t_strides=[1,2,2,1]\n",
    "    , z_dim= 2\n",
    ")\n",
    "\n",
    "if mode == 'build':\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n__________________________________________________________________________________________________\nencoder_conv_0 (Conv2D)         (None, 28, 28, 32)   320         encoder_input[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu (LeakyReLU)         (None, 28, 28, 32)   0           encoder_conv_0[0][0]             \n__________________________________________________________________________________________________\nencoder_conv_1 (Conv2D)         (None, 14, 14, 64)   18496       leaky_re_lu[0][0]                \n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 64)   0           encoder_conv_1[0][0]             \n__________________________________________________________________________________________________\nencoder_conv_2 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_1[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 64)     0           encoder_conv_2[0][0]             \n__________________________________________________________________________________________________\nencoder_conv_3 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_2[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 64)     0           encoder_conv_3[0][0]             \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 3136)         0           leaky_re_lu_3[0][0]              \n__________________________________________________________________________________________________\nmu (Dense)                      (None, 2)            6274        flatten[0][0]                    \n__________________________________________________________________________________________________\nlog_var (Dense)                 (None, 2)            6274        flatten[0][0]                    \n__________________________________________________________________________________________________\nencoder_output (Lambda)         (None, 2)            0           mu[0][0]                         \n                                                                 log_var[0][0]                    \n==================================================================================================\nTotal params: 105,220\nTrainable params: 105,220\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndecoder_input (InputLayer)   [(None, 2)]               0         \n_________________________________________________________________\ndense (Dense)                (None, 3136)              9408      \n_________________________________________________________________\nreshape (Reshape)            (None, 7, 7, 64)          0         \n_________________________________________________________________\ndecoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n_________________________________________________________________\ndecoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n_________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n_________________________________________________________________\ndecoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n_________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 32)        0         \n_________________________________________________________________\ndecoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n_________________________________________________________________\nactivation (Activation)      (None, 28, 28, 1)         0         \n=================================================================\nTotal params: 102,017\nTrainable params: 102,017\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 150\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "936/60000 [============================>.] - ETA: 0s - loss: 43.5894 - vae_r_loss: 38.1459 - vae_kl_loss: 5.4435\nEpoch 00103: saving model to run/vae/0002_digits\\weights/weights-103-43.59.h5\n\nEpoch 00103: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 256us/sample - loss: 43.5885 - vae_r_loss: 38.1448 - vae_kl_loss: 5.4438 - lr: 5.0000e-04\nEpoch 104/150\n59968/60000 [============================>.] - ETA: 0s - loss: 43.5830 - vae_r_loss: 38.1368 - vae_kl_loss: 5.4462\nEpoch 00104: saving model to run/vae/0002_digits\\weights/weights-104-43.58.h5\n\nEpoch 00104: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 248us/sample - loss: 43.5798 - vae_r_loss: 38.1335 - vae_kl_loss: 5.4463 - lr: 5.0000e-04\nEpoch 105/150\n59872/60000 [============================>.] - ETA: 0s - loss: 43.5705 - vae_r_loss: 38.1100 - vae_kl_loss: 5.4605\nEpoch 00105: saving model to run/vae/0002_digits\\weights/weights-105-43.57.h5\n\nEpoch 00105: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 256us/sample - loss: 43.5664 - vae_r_loss: 38.1058 - vae_kl_loss: 5.4607 - lr: 5.0000e-04\nEpoch 106/150\n59840/60000 [============================>.] - ETA: 0s - loss: 43.5755 - vae_r_loss: 38.1197 - vae_kl_loss: 5.4558\nEpoch 00106: saving model to run/vae/0002_digits\\weights/weights-106-43.58.h5\n\nEpoch 00106: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 249us/sample - loss: 43.5783 - vae_r_loss: 38.1225 - vae_kl_loss: 5.4558 - lr: 5.0000e-04\nEpoch 107/150\n59872/60000 [============================>.] - ETA: 0s - loss: 43.5564 - vae_r_loss: 38.1002 - vae_kl_loss: 5.4563\nEpoch 00107: saving model to run/vae/0002_digits\\weights/weights-107-43.56.h5\n\nEpoch 00107: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 247us/sample - loss: 43.5570 - vae_r_loss: 38.1010 - vae_kl_loss: 5.4560 - lr: 5.0000e-04\nEpoch 108/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.5531 - vae_r_loss: 38.1047 - vae_kl_loss: 5.4484\nEpoch 00108: saving model to run/vae/0002_digits\\weights/weights-108-43.55.h5\n\nEpoch 00108: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 249us/sample - loss: 43.5508 - vae_r_loss: 38.1022 - vae_kl_loss: 5.4486 - lr: 5.0000e-04\nEpoch 109/150\n59808/60000 [============================>.] - ETA: 0s - loss: 43.5247 - vae_r_loss: 38.0775 - vae_kl_loss: 5.4473\nEpoch 00109: saving model to run/vae/0002_digits\\weights/weights-109-43.52.h5\n\nEpoch 00109: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 248us/sample - loss: 43.5231 - vae_r_loss: 38.0755 - vae_kl_loss: 5.4477 - lr: 5.0000e-04\nEpoch 110/150\n59872/60000 [============================>.] - ETA: 0s - loss: 43.5013 - vae_r_loss: 38.0437 - vae_kl_loss: 5.4576\nEpoch 00110: saving model to run/vae/0002_digits\\weights/weights-110-43.50.h5\n\nEpoch 00110: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 251us/sample - loss: 43.4984 - vae_r_loss: 38.0408 - vae_kl_loss: 5.4576 - lr: 5.0000e-04\nEpoch 111/150\n59968/60000 [============================>.] - ETA: 0s - loss: 43.4908 - vae_r_loss: 38.0481 - vae_kl_loss: 5.4427\nEpoch 00111: saving model to run/vae/0002_digits\\weights/weights-111-43.49.h5\n\nEpoch 00111: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 251us/sample - loss: 43.4906 - vae_r_loss: 38.0477 - vae_kl_loss: 5.4429 - lr: 5.0000e-04\nEpoch 112/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.4874 - vae_r_loss: 38.0349 - vae_kl_loss: 5.4524\nEpoch 00112: saving model to run/vae/0002_digits\\weights/weights-112-43.48.h5\n\nEpoch 00112: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 257us/sample - loss: 43.4824 - vae_r_loss: 38.0299 - vae_kl_loss: 5.4525 - lr: 5.0000e-04\nEpoch 113/150\n59936/60000 [============================>.] - ETA: 0s - loss: 43.4873 - vae_r_loss: 38.0290 - vae_kl_loss: 5.4584\nEpoch 00113: saving model to run/vae/0002_digits\\weights/weights-113-43.49.h5\n\nEpoch 00113: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 256us/sample - loss: 43.4895 - vae_r_loss: 38.0310 - vae_kl_loss: 5.4585 - lr: 5.0000e-04\nEpoch 114/150\n60000/60000 [==============================] - ETA: 0s - loss: 43.5133 - vae_r_loss: 38.0531 - vae_kl_loss: 5.4602\nEpoch 00114: saving model to run/vae/0002_digits\\weights/weights-114-43.51.h5\n\nEpoch 00114: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 257us/sample - loss: 43.5133 - vae_r_loss: 38.0531 - vae_kl_loss: 5.4602 - lr: 5.0000e-04\nEpoch 115/150\n59872/60000 [============================>.] - ETA: 0s - loss: 43.4705 - vae_r_loss: 38.0122 - vae_kl_loss: 5.4583\nEpoch 00115: saving model to run/vae/0002_digits\\weights/weights-115-43.47.h5\n\nEpoch 00115: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 257us/sample - loss: 43.4690 - vae_r_loss: 38.0107 - vae_kl_loss: 5.4583 - lr: 5.0000e-04\nEpoch 116/150\n59840/60000 [============================>.] - ETA: 0s - loss: 43.4819 - vae_r_loss: 38.0130 - vae_kl_loss: 5.4688\nEpoch 00116: saving model to run/vae/0002_digits\\weights/weights-116-43.49.h5\n\nEpoch 00116: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 257us/sample - loss: 43.4878 - vae_r_loss: 38.0191 - vae_kl_loss: 5.4687 - lr: 5.0000e-04\nEpoch 117/150\n59808/60000 [============================>.] - ETA: 0s - loss: 43.4560 - vae_r_loss: 37.9790 - vae_kl_loss: 5.4770\nEpoch 00117: saving model to run/vae/0002_digits\\weights/weights-117-43.45.h5\n\nEpoch 00117: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 254us/sample - loss: 43.4490 - vae_r_loss: 37.9720 - vae_kl_loss: 5.4770 - lr: 5.0000e-04\nEpoch 118/150\n59936/60000 [============================>.] - ETA: 0s - loss: 43.4579 - vae_r_loss: 37.9842 - vae_kl_loss: 5.4738\nEpoch 00118: saving model to run/vae/0002_digits\\weights/weights-118-43.46.h5\n\nEpoch 00118: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 268us/sample - loss: 43.4608 - vae_r_loss: 37.9871 - vae_kl_loss: 5.4738 - lr: 5.0000e-04\nEpoch 119/150\n59840/60000 [============================>.] - ETA: 0s - loss: 43.4525 - vae_r_loss: 37.9905 - vae_kl_loss: 5.4620\nEpoch 00119: saving model to run/vae/0002_digits\\weights/weights-119-43.45.h5\n\nEpoch 00119: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 267us/sample - loss: 43.4526 - vae_r_loss: 37.9908 - vae_kl_loss: 5.4618 - lr: 5.0000e-04\nEpoch 120/150\n60000/60000 [==============================] - ETA: 0s - loss: 43.4445 - vae_r_loss: 37.9843 - vae_kl_loss: 5.4603\nEpoch 00120: saving model to run/vae/0002_digits\\weights/weights-120-43.44.h5\n\nEpoch 00120: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 253us/sample - loss: 43.4445 - vae_r_loss: 37.9843 - vae_kl_loss: 5.4603 - lr: 5.0000e-04\nEpoch 121/150\n59968/60000 [============================>.] - ETA: 0s - loss: 43.4071 - vae_r_loss: 37.9519 - vae_kl_loss: 5.4552\nEpoch 00121: saving model to run/vae/0002_digits\\weights/weights-121-43.41.h5\n\nEpoch 00121: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 251us/sample - loss: 43.4093 - vae_r_loss: 37.9542 - vae_kl_loss: 5.4551 - lr: 5.0000e-04\nEpoch 122/150\n59840/60000 [============================>.] - ETA: 0s - loss: 43.3981 - vae_r_loss: 37.9320 - vae_kl_loss: 5.4661\nEpoch 00122: saving model to run/vae/0002_digits\\weights/weights-122-43.39.h5\n\nEpoch 00122: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 249us/sample - loss: 43.3937 - vae_r_loss: 37.9273 - vae_kl_loss: 5.4664 - lr: 5.0000e-04\nEpoch 123/150\n59840/60000 [============================>.] - ETA: 0s - loss: 43.4253 - vae_r_loss: 37.9386 - vae_kl_loss: 5.4867\nEpoch 00123: saving model to run/vae/0002_digits\\weights/weights-123-43.42.h5\n\nEpoch 00123: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 248us/sample - loss: 43.4238 - vae_r_loss: 37.9371 - vae_kl_loss: 5.4867 - lr: 5.0000e-04\nEpoch 124/150\n59936/60000 [============================>.] - ETA: 0s - loss: 43.4059 - vae_r_loss: 37.9327 - vae_kl_loss: 5.4732\nEpoch 00124: saving model to run/vae/0002_digits\\weights/weights-124-43.41.h5\n\nEpoch 00124: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 248us/sample - loss: 43.4090 - vae_r_loss: 37.9359 - vae_kl_loss: 5.4731 - lr: 5.0000e-04\nEpoch 125/150\n59872/60000 [============================>.] - ETA: 0s - loss: 43.3830 - vae_r_loss: 37.9160 - vae_kl_loss: 5.4670\nEpoch 00125: saving model to run/vae/0002_digits\\weights/weights-125-43.38.h5\n\nEpoch 00125: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 253us/sample - loss: 43.3811 - vae_r_loss: 37.9138 - vae_kl_loss: 5.4673 - lr: 5.0000e-04\nEpoch 126/150\n59968/60000 [============================>.] - ETA: 0s - loss: 43.4032 - vae_r_loss: 37.9289 - vae_kl_loss: 5.4743\nEpoch 00126: saving model to run/vae/0002_digits\\weights/weights-126-43.41.h5\n\nEpoch 00126: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 249us/sample - loss: 43.4070 - vae_r_loss: 37.9327 - vae_kl_loss: 5.4744 - lr: 5.0000e-04\nEpoch 127/150\n59840/60000 [============================>.] - ETA: 0s - loss: 43.4052 - vae_r_loss: 37.9165 - vae_kl_loss: 5.4887\nEpoch 00127: saving model to run/vae/0002_digits\\weights/weights-127-43.40.h5\n\nEpoch 00127: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 249us/sample - loss: 43.4003 - vae_r_loss: 37.9113 - vae_kl_loss: 5.4889 - lr: 5.0000e-04\nEpoch 128/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.3553 - vae_r_loss: 37.8691 - vae_kl_loss: 5.4862\nEpoch 00128: saving model to run/vae/0002_digits\\weights/weights-128-43.36.h5\n\nEpoch 00128: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 248us/sample - loss: 43.3593 - vae_r_loss: 37.8733 - vae_kl_loss: 5.4861 - lr: 5.0000e-04\nEpoch 129/150\n60000/60000 [==============================] - ETA: 0s - loss: 43.3562 - vae_r_loss: 37.8780 - vae_kl_loss: 5.4782\nEpoch 00129: saving model to run/vae/0002_digits\\weights/weights-129-43.36.h5\n\nEpoch 00129: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 253us/sample - loss: 43.3562 - vae_r_loss: 37.8780 - vae_kl_loss: 5.4782 - lr: 5.0000e-04\nEpoch 130/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.3464 - vae_r_loss: 37.8667 - vae_kl_loss: 5.4796\nEpoch 00130: saving model to run/vae/0002_digits\\weights/weights-130-43.35.h5\n\nEpoch 00130: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 253us/sample - loss: 43.3467 - vae_r_loss: 37.8670 - vae_kl_loss: 5.4797 - lr: 5.0000e-04\nEpoch 131/150\n59808/60000 [============================>.] - ETA: 0s - loss: 43.3756 - vae_r_loss: 37.8932 - vae_kl_loss: 5.4823\nEpoch 00131: saving model to run/vae/0002_digits\\weights/weights-131-43.37.h5\n\nEpoch 00131: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 262us/sample - loss: 43.3732 - vae_r_loss: 37.8911 - vae_kl_loss: 5.4821 - lr: 5.0000e-04\nEpoch 132/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.3575 - vae_r_loss: 37.8683 - vae_kl_loss: 5.4891\nEpoch 00132: saving model to run/vae/0002_digits\\weights/weights-132-43.36.h5\n\nEpoch 00132: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 251us/sample - loss: 43.3581 - vae_r_loss: 37.8687 - vae_kl_loss: 5.4893 - lr: 5.0000e-04\nEpoch 133/150\n59872/60000 [============================>.] - ETA: 0s - loss: 43.3399 - vae_r_loss: 37.8568 - vae_kl_loss: 5.4831\nEpoch 00133: saving model to run/vae/0002_digits\\weights/weights-133-43.34.h5\n\nEpoch 00133: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 252us/sample - loss: 43.3415 - vae_r_loss: 37.8586 - vae_kl_loss: 5.4830 - lr: 5.0000e-04\nEpoch 134/150\n59872/60000 [============================>.] - ETA: 0s - loss: 43.3551 - vae_r_loss: 37.8596 - vae_kl_loss: 5.4955\nEpoch 00134: saving model to run/vae/0002_digits\\weights/weights-134-43.36.h5\n\nEpoch 00134: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 253us/sample - loss: 43.3585 - vae_r_loss: 37.8629 - vae_kl_loss: 5.4956 - lr: 5.0000e-04\nEpoch 135/150\n59808/60000 [============================>.] - ETA: 0s - loss: 43.3249 - vae_r_loss: 37.8383 - vae_kl_loss: 5.4866\nEpoch 00135: saving model to run/vae/0002_digits\\weights/weights-135-43.32.h5\n\nEpoch 00135: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 249us/sample - loss: 43.3241 - vae_r_loss: 37.8377 - vae_kl_loss: 5.4864 - lr: 5.0000e-04\nEpoch 136/150\n59936/60000 [============================>.] - ETA: 0s - loss: 43.3573 - vae_r_loss: 37.8702 - vae_kl_loss: 5.4871\nEpoch 00136: saving model to run/vae/0002_digits\\weights/weights-136-43.36.h5\n\nEpoch 00136: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 250us/sample - loss: 43.3578 - vae_r_loss: 37.8707 - vae_kl_loss: 5.4872 - lr: 5.0000e-04\nEpoch 137/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.3008 - vae_r_loss: 37.8119 - vae_kl_loss: 5.4889\nEpoch 00137: saving model to run/vae/0002_digits\\weights/weights-137-43.30.h5\n\nEpoch 00137: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 251us/sample - loss: 43.3013 - vae_r_loss: 37.8125 - vae_kl_loss: 5.4889 - lr: 5.0000e-04\nEpoch 138/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.3150 - vae_r_loss: 37.8238 - vae_kl_loss: 5.4912\nEpoch 00138: saving model to run/vae/0002_digits\\weights/weights-138-43.31.h5\n\nEpoch 00138: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 252us/sample - loss: 43.3136 - vae_r_loss: 37.8226 - vae_kl_loss: 5.4910 - lr: 5.0000e-04\nEpoch 139/150\n60000/60000 [==============================] - ETA: 0s - loss: 43.2980 - vae_r_loss: 37.7968 - vae_kl_loss: 5.5012\nEpoch 00139: saving model to run/vae/0002_digits\\weights/weights-139-43.30.h5\n\nEpoch 00139: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 247us/sample - loss: 43.2980 - vae_r_loss: 37.7968 - vae_kl_loss: 5.5012 - lr: 5.0000e-04\nEpoch 140/150\n59840/60000 [============================>.] - ETA: 0s - loss: 43.2794 - vae_r_loss: 37.7943 - vae_kl_loss: 5.4850\nEpoch 00140: saving model to run/vae/0002_digits\\weights/weights-140-43.28.h5\n\nEpoch 00140: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 254us/sample - loss: 43.2751 - vae_r_loss: 37.7900 - vae_kl_loss: 5.4851 - lr: 5.0000e-04\nEpoch 141/150\n59872/60000 [============================>.] - ETA: 0s - loss: 43.3097 - vae_r_loss: 37.8191 - vae_kl_loss: 5.4906\nEpoch 00141: saving model to run/vae/0002_digits\\weights/weights-141-43.31.h5\n\nEpoch 00141: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 253us/sample - loss: 43.3088 - vae_r_loss: 37.8182 - vae_kl_loss: 5.4906 - lr: 5.0000e-04\nEpoch 142/150\n59936/60000 [============================>.] - ETA: 0s - loss: 43.3133 - vae_r_loss: 37.8129 - vae_kl_loss: 5.5003\nEpoch 00142: saving model to run/vae/0002_digits\\weights/weights-142-43.31.h5\n\nEpoch 00142: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 15s 255us/sample - loss: 43.3132 - vae_r_loss: 37.8127 - vae_kl_loss: 5.5005 - lr: 5.0000e-04\nEpoch 143/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.2550 - vae_r_loss: 37.7634 - vae_kl_loss: 5.4916\nEpoch 00143: saving model to run/vae/0002_digits\\weights/weights-143-43.26.h5\n\nEpoch 00143: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 261us/sample - loss: 43.2568 - vae_r_loss: 37.7652 - vae_kl_loss: 5.4916 - lr: 5.0000e-04\nEpoch 144/150\n59936/60000 [============================>.] - ETA: 0s - loss: 43.2768 - vae_r_loss: 37.7916 - vae_kl_loss: 5.4852\nEpoch 00144: saving model to run/vae/0002_digits\\weights/weights-144-43.28.h5\n\nEpoch 00144: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 268us/sample - loss: 43.2806 - vae_r_loss: 37.7955 - vae_kl_loss: 5.4851 - lr: 5.0000e-04\nEpoch 145/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.2581 - vae_r_loss: 37.7561 - vae_kl_loss: 5.5021\nEpoch 00145: saving model to run/vae/0002_digits\\weights/weights-145-43.26.h5\n\nEpoch 00145: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 268us/sample - loss: 43.2574 - vae_r_loss: 37.7553 - vae_kl_loss: 5.5021 - lr: 5.0000e-04\nEpoch 146/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.2860 - vae_r_loss: 37.7868 - vae_kl_loss: 5.4991\nEpoch 00146: saving model to run/vae/0002_digits\\weights/weights-146-43.28.h5\n\nEpoch 00146: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 261us/sample - loss: 43.2810 - vae_r_loss: 37.7819 - vae_kl_loss: 5.4991 - lr: 5.0000e-04\nEpoch 147/150\n59936/60000 [============================>.] - ETA: 0s - loss: 43.2350 - vae_r_loss: 37.7302 - vae_kl_loss: 5.5049\nEpoch 00147: saving model to run/vae/0002_digits\\weights/weights-147-43.24.h5\n\nEpoch 00147: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 270us/sample - loss: 43.2380 - vae_r_loss: 37.7331 - vae_kl_loss: 5.5049 - lr: 5.0000e-04\nEpoch 148/150\n59904/60000 [============================>.] - ETA: 0s - loss: 43.2810 - vae_r_loss: 37.7646 - vae_kl_loss: 5.5164\nEpoch 00148: saving model to run/vae/0002_digits\\weights/weights-148-43.28.h5\n\nEpoch 00148: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 269us/sample - loss: 43.2786 - vae_r_loss: 37.7622 - vae_kl_loss: 5.5164 - lr: 5.0000e-04\nEpoch 149/150\n59808/60000 [============================>.] - ETA: 0s - loss: 43.2153 - vae_r_loss: 37.7028 - vae_kl_loss: 5.5124\nEpoch 00149: saving model to run/vae/0002_digits\\weights/weights-149-43.22.h5\n\nEpoch 00149: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 17s 276us/sample - loss: 43.2197 - vae_r_loss: 37.7072 - vae_kl_loss: 5.5125 - lr: 5.0000e-04\nEpoch 150/150\n59936/60000 [============================>.] - ETA: 0s - loss: 43.2099 - vae_r_loss: 37.6951 - vae_kl_loss: 5.5149\nEpoch 00150: saving model to run/vae/0002_digits\\weights/weights-150-43.21.h5\n\nEpoch 00150: saving model to run/vae/0002_digits\\weights/weights.h5\n60000/60000 [==============================] - 16s 263us/sample - loss: 43.2109 - vae_r_loss: 37.6962 - vae_kl_loss: 5.5146 - lr: 5.0000e-04\n"
    }
   ],
   "source": [
    "vae.train(\n",
    "    x_train=x_train,\n",
    "    batch_size= BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    run_folder= RUN_FOLDER,\n",
    "    print_every_n_batches=PRINT_EVERY_N_BATCHES,\n",
    "    initial_epoch=INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "generative",
   "display_name": "generative"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}